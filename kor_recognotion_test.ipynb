{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7058d854-89df-4117-9aff-020a8dd331a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hyunsubong/opt/anaconda3/envs/hyun_ml/lib/python3.9/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: dlopen(/Users/hyunsubong/opt/anaconda3/envs/hyun_ml/lib/python3.9/site-packages/torchvision/image.so, 0x0006): Symbol not found: __ZN2at4_ops19empty_memory_format4callEN3c108ArrayRefIxEENS2_8optionalINS2_10ScalarTypeEEENS5_INS2_6LayoutEEENS5_INS2_6DeviceEEENS5_IbEENS5_INS2_12MemoryFormatEEE\n",
      "  Referenced from: <CAE66874-17C2-35C9-9C4D-6BA9770AF17F> /Users/hyunsubong/opt/anaconda3/envs/hyun_ml/lib/python3.9/site-packages/torchvision/image.so\n",
      "  Expected in:     <7AB234BF-29E3-390D-8C8D-C6920F94393C> /Users/hyunsubong/opt/anaconda3/envs/hyun_ml/lib/python3.9/site-packages/torch/lib/libtorch_cpu.dylib\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n",
      "/var/folders/97/h6gs8h1d6k14yqbrgsk0nrw80000gn/T/ipykernel_84582/534817885.py:3: DeprecationWarning: Importing display from IPython.core.display is deprecated since IPython 7.14, please import from IPython display\n",
      "  from IPython.core.display import display, HTML\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from IPython.core.display import display, HTML\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import base64\n",
    "import io\n",
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "import re\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14c246b7",
   "metadata": {},
   "source": [
    "# CRAFT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb797685",
   "metadata": {},
   "source": [
    "### Ubuntu 22.04 LTS CUDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "162c1ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "craft = !CUDA_VISIBLE_DEVICES=0 python3 craft/craft_test.py \\\n",
    "            --trained_model=\"./weights/craft/craft_mlt_25k.pth\" \\\n",
    "            --refiner_model=\"./weights/craft/craft_refiner_CTW1500.pth\" \\\n",
    "            --test_folder=\"./data/test_img/IMG_1257/\" \\\n",
    "            --cuda=True \\\n",
    "            --mps=False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be1f86ef",
   "metadata": {},
   "source": [
    "### Apple Silicon Mps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0dd04add",
   "metadata": {},
   "outputs": [],
   "source": [
    "craft = !python craft/craft_test.py \\\n",
    "            --trained_model=\"./weights/craft/craft_mlt_25k.pth\" \\\n",
    "            --refiner_model=\"./weights/craft/craft_refiner_CTW1500.pth\" \\\n",
    "            --test_folder=\"./data/test_img/IMG_1331/\" \\\n",
    "            --cuda=False \\\n",
    "            --mps=True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02345793",
   "metadata": {},
   "source": [
    "# Dialogue crop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "82532d87-cea6-4224-be35-f44025320065",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/Users/hyunsubong/opt/anaconda3/envs/hyun_ml/lib/python3.9/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: dlopen(/Users/hyunsubong/opt/anaconda3/envs/hyun_ml/lib/python3.9/site-packages/torchvision/image.so, 0x0006): Symbol not found: __ZN2at4_ops19empty_memory_format4callEN3c108ArrayRefIxEENS2_8optionalINS2_10ScalarTypeEEENS5_INS2_6LayoutEEENS5_INS2_6DeviceEEENS5_IbEENS5_INS2_12MemoryFormatEEE',\n",
       " '  Referenced from: <CAE66874-17C2-35C9-9C4D-6BA9770AF17F> /Users/hyunsubong/opt/anaconda3/envs/hyun_ml/lib/python3.9/site-packages/torchvision/image.so',\n",
       " '  Expected in:     <7AB234BF-29E3-390D-8C8D-C6920F94393C> /Users/hyunsubong/opt/anaconda3/envs/hyun_ml/lib/python3.9/site-packages/torch/lib/libtorch_cpu.dylib',\n",
       " '  warn(f\"Failed to load image Python extension: {e}\")',\n",
       " '/Users/hyunsubong/opt/anaconda3/envs/hyun_ml/lib/python3.9/site-packages/torchvision/models/_utils.py:252: UserWarning: Accessing the model URLs via the internal dictionary of the module is deprecated since 0.13 and will be removed in 0.15. Please access them via the appropriate Weights Enum instead.',\n",
       " '  warnings.warn(',\n",
       " \"/Users/hyunsubong/opt/anaconda3/envs/hyun_ml/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=None`.\",\n",
       " '  warnings.warn(msg)',\n",
       " 'torch device : mps',\n",
       " 'Loading weights from checkpoint (./weights/craft/craft_mlt_25k.pth)',\n",
       " 'Test image 1/1: ./data/test_img/IMG_1331/IMG_1331.PNG',\n",
       " 'elapsed time : 0.4588768482208252s']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "craft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5370fd4d-688b-471f-a21e-a0fc21d4be01",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMG_1331.PNG\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'151,63,279,63,279,115,151,115'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_img_dir = './data/test_img/IMG_1331/'\n",
    "image_bbox_dir = input_img_dir + 'result/'\n",
    "image_path = ''\n",
    "filename = ''\n",
    "\n",
    "for idx in range(len(craft)):\n",
    "    try:\n",
    "        ind = craft[idx].index(input_img_dir)\n",
    "        filename = craft[idx][ind+len(input_img_dir):]\n",
    "        print(filename)\n",
    "        image_path = input_img_dir + filename\n",
    "    except:\n",
    "        continue\n",
    "        \n",
    "image_bbox_path = f\"{image_bbox_dir}res_{filename[:-4]}.txt\"\n",
    "image_bbox = open(image_bbox_path, 'r')\n",
    "image_bbox = image_bbox.read().splitlines()\n",
    "\n",
    "image_bbox[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e1843d33-0172-4e45-a1f1-1c399442525f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['151', '63', '279', '63', '279', '115', '151', '115']\n"
     ]
    }
   ],
   "source": [
    "print(image_bbox[0].split(','))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ea66ad0d-406e-4170-be66-3d7172ba5bea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "image_bbox_int = []\n",
    "for idx in range(len(image_bbox)):\n",
    "    temp = image_bbox[idx].split(',')\n",
    "    image_bbox_int.append(list(map(int, temp)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a57c0a8a-37e6-49b5-a3f2-19b6e2a8e9fc",
   "metadata": {},
   "source": [
    "## Boundingbox 정렬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dd61f905-036b-47df-be14-865a410d180e",
   "metadata": {},
   "outputs": [],
   "source": [
    "image1 = Image.open(image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "655130cc-1ddd-4654-b2ce-9839cf8fe3b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_box_precedence(box, cols):\n",
    "    tolerance_factor = 30\n",
    "    return ((box[1] // tolerance_factor) * tolerance_factor) * cols + box[0]\n",
    "\n",
    "def get_sorted_bb(boxes, img_shape):\n",
    "    sorted_boxes = sorted(boxes, key=lambda x: get_box_precedence(x, img_shape[1]))\n",
    "    return sorted_boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f943603f-de56-4b82-a565-4c96f13e45fe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "image_bbox_int = get_sorted_bb(image_bbox_int, image1.size)\n",
    "# sorted_boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0d486979",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[151, 63, 279, 63, 279, 115, 151, 115]\n",
      "[922, 71, 978, 71, 978, 107, 922, 107]\n",
      "[95, 203, 179, 203, 179, 247, 95, 247]\n",
      "[523, 199, 654, 199, 654, 255, 523, 255]\n",
      "[152, 326, 249, 332, 246, 373, 149, 367]\n",
      "[183, 415, 383, 415, 383, 467, 183, 467]\n",
      "[387, 419, 519, 419, 519, 467, 387, 467]\n",
      "[523, 419, 635, 419, 635, 459, 523, 459]\n",
      "[642, 415, 762, 415, 762, 471, 642, 471]\n",
      "[766, 415, 846, 415, 846, 467, 766, 467]\n",
      "[850, 419, 934, 419, 934, 467, 850, 467]\n",
      "[183, 471, 263, 471, 263, 523, 183, 523]\n",
      "[267, 471, 395, 471, 395, 523, 267, 523]\n",
      "[974, 511, 1050, 511, 1050, 547, 974, 547]\n",
      "[1050, 515, 1098, 515, 1098, 547, 1050, 547]\n",
      "[806, 623, 974, 623, 974, 666, 806, 666]\n",
      "[978, 623, 1138, 623, 1138, 674, 978, 674]\n",
      "[642, 666, 714, 666, 714, 694, 642, 694]\n",
      "[718, 662, 766, 662, 766, 694, 718, 694]\n",
      "[694, 746, 774, 746, 774, 786, 694, 786]\n",
      "[781, 746, 977, 740, 979, 794, 783, 801]\n",
      "[986, 754, 1126, 754, 1126, 782, 986, 782]\n",
      "[535, 790, 611, 790, 611, 818, 535, 818]\n",
      "[619, 790, 662, 790, 662, 818, 619, 818]\n",
      "[152, 861, 249, 867, 246, 908, 149, 902]\n",
      "[467, 950, 631, 950, 631, 994, 467, 994]\n",
      "[187, 962, 407, 962, 407, 994, 187, 994]\n",
      "[674, 998, 730, 998, 730, 1026, 674, 1026]\n",
      "[734, 998, 778, 998, 778, 1026, 734, 1026]\n",
      "[579, 1102, 658, 1102, 658, 1146, 579, 1146]\n",
      "[662, 1102, 782, 1102, 782, 1154, 662, 1154]\n",
      "[786, 1102, 906, 1102, 906, 1154, 786, 1154]\n",
      "[906, 1102, 950, 1102, 950, 1150, 906, 1150]\n",
      "[954, 1098, 1138, 1098, 1138, 1154, 954, 1154]\n",
      "[439, 1150, 495, 1150, 495, 1178, 439, 1178]\n",
      "[499, 1146, 547, 1146, 547, 1174, 499, 1174]\n",
      "[151, 1222, 247, 1222, 247, 1262, 151, 1262]\n",
      "[187, 1309, 219, 1309, 219, 1357, 187, 1357]\n",
      "[227, 1313, 251, 1313, 251, 1329, 227, 1329]\n",
      "[263, 1309, 423, 1309, 423, 1361, 263, 1361]\n",
      "[423, 1305, 583, 1305, 583, 1361, 423, 1361]\n",
      "[595, 1317, 694, 1317, 694, 1345, 595, 1345]\n",
      "[227, 1329, 255, 1329, 255, 1357, 227, 1357]\n",
      "[802, 1349, 850, 1349, 850, 1381, 802, 1381]\n",
      "[742, 1353, 802, 1353, 802, 1381, 742, 1381]\n",
      "[982, 1457, 1134, 1457, 1134, 1509, 982, 1509]\n",
      "[834, 1505, 894, 1505, 894, 1533, 834, 1533]\n",
      "[898, 1505, 946, 1505, 946, 1533, 898, 1533]\n",
      "[151, 1577, 247, 1577, 247, 1617, 151, 1617]\n",
      "[183, 1665, 303, 1665, 303, 1717, 183, 1717]\n",
      "[303, 1665, 471, 1665, 471, 1717, 303, 1717]\n",
      "[507, 1713, 567, 1713, 567, 1741, 507, 1741]\n",
      "[575, 1713, 619, 1713, 619, 1741, 575, 1741]\n",
      "[978, 1817, 1130, 1817, 1130, 1861, 978, 1861]\n",
      "[986, 1948, 1126, 1948, 1126, 1976, 986, 1976]\n",
      "[834, 1984, 894, 1984, 894, 2012, 834, 2012]\n",
      "[894, 1980, 942, 1980, 942, 2012, 894, 2012]\n",
      "[151, 2056, 247, 2056, 247, 2100, 151, 2100]\n",
      "[187, 2156, 635, 2156, 635, 2184, 187, 2184]\n",
      "[639, 2144, 862, 2144, 862, 2192, 639, 2192]\n",
      "[866, 2144, 906, 2144, 906, 2188, 866, 2188]\n",
      "[179, 2200, 295, 2200, 295, 2252, 179, 2252]\n",
      "[950, 2244, 1010, 2244, 1010, 2272, 950, 2272]\n",
      "[1010, 2244, 1046, 2244, 1046, 2272, 1010, 2272]\n",
      "[1054, 2364, 1106, 2364, 1106, 2420, 1054, 2420]\n"
     ]
    }
   ],
   "source": [
    "image1 = Image.open(image_path)\n",
    "for idx, bboxs in enumerate(image_bbox_int):\n",
    "    print(bboxs)\n",
    "    x = bboxs[0]\n",
    "    y = bboxs[1]\n",
    "    x2 = bboxs[4]\n",
    "    y2 = bboxs[5]\n",
    "    \n",
    "    # crop(죄측 상단 x,y , 우측 하단 x,y)\n",
    "    croppedImage = image1.crop((x, y, x2, y2))\n",
    "    \n",
    "    if not os.path.isdir(f\"{input_img_dir}crop\"):\n",
    "        os.mkdir(f\"{input_img_dir}crop\")\n",
    "    croppedImage.save(f\"{input_img_dir}crop/crop_{filename[:-4]}_{idx}.PNG\")\n",
    "\n",
    "# [974, 615, 1130, 615, 1130, 666, 974, 666] # 오\n",
    "#  [774, 623, 806, 623, 806, 658, 774, 658] # 좋지 좋지\n",
    "# y 차이가 8이하면 같은 줄이라 판단\n",
    "\n",
    "#[391, 962, 415, 962, 415, 986, 391, 986],\n",
    "# [571, 946, 666, 946, 666, 990, 571, 990])\n",
    "# y 차이 16"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8b98c94",
   "metadata": {
    "tags": []
   },
   "source": [
    "# TPS-ResNet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40200f61-6360-40b6-afc8-3e2ccfc47760",
   "metadata": {},
   "source": [
    "### Ubuntu 22.04 LTS CUDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "020c9b51-53c2-402d-a183-454fe7c4bfa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "recognition = !CUDA_VISIBLE_DEVICES=0 python3 tps-resnet/demo.py \\\n",
    "                        --Transformation TPS --FeatureExtraction VGG --SequenceModeling BiLSTM --Prediction Attn \\\n",
    "                        --image_folder=\"data/test_img/IMG_1257/crop/\" \\\n",
    "                        --saved_model=\"weights/TPS-ResNet/pretrained/best.pth\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "579a3638-dd7b-4caa-89d5-b490601e964a",
   "metadata": {},
   "source": [
    "### Apple Silicon Mps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "353e6dee-cff6-4779-a9cd-b6dc1544c9d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# output = !python tps-resnet/demo.py \\\n",
    "#                     --Transformation TPS --FeatureExtraction VGG --SequenceModeling BiLSTM --Prediction Attn \\\n",
    "#                     --image_folder=\"data/test_img/IMG_1257/crop/\" \\\n",
    "#                     --saved_model=\"weights/TPS-ResNet/pretrained/best.pth\"\n",
    "!python tps-resnet/demo.py \\\n",
    "                    --Transformation TPS --FeatureExtraction VGG --SequenceModeling BiLSTM --Prediction Attn \\\n",
    "                    --image_folder=\"data/test_img/IMG_1257/crop/\" \\\n",
    "                    --saved_model=\"weights/TPS-ResNet/pretrained/best.pth\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f58317b",
   "metadata": {},
   "source": [
    "# Dialogue Summarize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e4e8d893-1f36-42d1-8df0-dfb1606787d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('json_sample.json', encoding='utf-8') as data:\n",
    "        json_data = json.load(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "03bb202f-11ae-47bc-b5ef-dc0b99f2bd95",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "images_ls = json_data.get('images')\n",
    "fields_ls = images_ls[0]['fields']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e24e4dd2-4928-44bf-b256-030ec72b376f",
   "metadata": {},
   "outputs": [],
   "source": [
    "bbox_ls = []\n",
    "for idx, field in enumerate(fields_ls):\n",
    "    bbox_temp = []\n",
    "    inferText = field['inferText']\n",
    "    boundingPoly = field['boundingPoly']['vertices']\n",
    "    \n",
    "    # 왼쪽 위, 오른쪽 위, 오른쪽 아래,왼쪽 아래 로 저장\n",
    "    for vertice in boundingPoly[0:]:\n",
    "        x = vertice['x']\n",
    "        y = vertice['y']\n",
    "        bbox_temp.append(int(x))\n",
    "        bbox_temp.append(int(y))\n",
    "    \n",
    "    bbox_temp.append(inferText)\n",
    "    \n",
    "    bbox_ls.append(bbox_temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cee6303b-1579-49d2-b063-62f24840ae12",
   "metadata": {},
   "source": [
    "## 한글인지 확인"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0880eff-8062-455f-b851-88fac525ac7c",
   "metadata": {},
   "source": [
    "##### 처음 나오는 한글이라면 대화 상대이므로 이 대화 상대가 대화 시간 이후로 처음 나오는 경우에는 제거대상"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "038f2ef5-91ae-4cba-b16a-2d6a2ff47644",
   "metadata": {},
   "outputs": [],
   "source": [
    "def isHangul(text):\n",
    "    #Check the Python Version\n",
    "    pyVer3 =  sys.version_info >= (3, 0)\n",
    "\n",
    "    if pyVer3 : # for Ver 3 or later\n",
    "        encText = text\n",
    "    else: # for Ver 2.x\n",
    "        if type(text) is not unicode:\n",
    "            encText = text.decode('utf-8')\n",
    "        else:\n",
    "            encText = text\n",
    "\n",
    "    hanCount = len(re.findall(u'[\\u3130-\\u318F\\uAC00-\\uD7A3]+', encText))\n",
    "    return hanCount > 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a5f1421-6897-41c5-9c97-c44232c3054e",
   "metadata": {},
   "source": [
    "## 대화만 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ce720612-f3cc-48ee-9f56-daeeb1eedee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "participant = ''\n",
    "for idx, row in enumerate(bbox_ls):\n",
    "    if isHangul(row[-1]) == True:\n",
    "        participant = row[-1]\n",
    "        bbox_ls = bbox_ls[idx+1:]\n",
    "        break\n",
    "\n",
    "new_bbox_ls = []\n",
    "dialogue = []\n",
    "for idx, row in enumerate(bbox_ls):\n",
    "    if row[-1] == participant:\n",
    "        continue\n",
    "    elif row[-1] == 'PM' or row[-1] == 'AM':\n",
    "        new_bbox_ls.append(dialogue)\n",
    "        dialogue = []\n",
    "        continue\n",
    "    elif row[-1] in ':':\n",
    "        continue\n",
    "    \n",
    "    if isHangul(row[-1]):\n",
    "        dialogue.append(row[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "54030b83-729e-4343-9290-f5696980095d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['얌', '도은이랑', '5/21에', '보기로', '했는데너도', '시간', '되면', '올랴??'],\n",
       " ['그래??', '좋지좋지'],\n",
       " ['되게만들어야지'],\n",
       " ['크', '오키오키!'],\n",
       " ['아직', '어디서', '볼지는', '안', '정한거지?'],\n",
       " ['웅웅', '날짜밖에', '안정했어', '크', '크', '크'],\n",
       " ['부발역은'],\n",
       " ['어디가', '좋은데??'],\n",
       " ['안되나요', '크']]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_bbox_ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6359faab-47b1-4abb-a2f8-b5763d748b75",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
